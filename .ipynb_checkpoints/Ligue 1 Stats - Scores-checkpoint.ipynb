{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to retrieve L1 results from ligue1.com website and save it down as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.html as lh\n",
    "import lxml.etree as et\n",
    "import urllib.request as ulib\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "import logging\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = 'L:/Dev/Sandbox/Apps Development/SoccerStats/historical result files/France'\n",
    "dic_competition_url = {'ligue1': 'ligue1', 'coupe-de-la-ligue': 'coupeLigue', 'trophee-des-champions': 'tropheeChampions'}\n",
    "week_counter = {'coupe-de-la-ligue': [47,48,56,57,58,59,60], 'trophee-des-champions': [-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('myapp')\n",
    "hdlr = logging.FileHandler(os.path.join(root_path,'ligue1comScoreRetriever.log'))\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logger.error(\"test error\")\n",
    "#logger.warning(\"this is a warning\")\n",
    "#logger.info(\"this is just info\")\n",
    "#logger.debug(\"this is debug\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [save_obj] && [load_obj] save/load object in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create season dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dic = {'2017/2018': '101', '2016/2017': '100', '2015/2016': '84', '2014/2015': '83', '2013/2014': '82', '2012/2013': '81', '2011/2012': '80', '2010/2011': '79', '2009/2010': '78', '2008/2009': '77', '2007/2008': '76', '2006/2007': '75', '2005/2006': '74', '2004/2005': '73', '2003/2004': '72', '2002/2003': '71', '2001/2002': '70', '2000/2001': '69', '1999/2000': '68', '1998/1999': '67', '1997/1998': '66', '1996/1997': '65', '1995/1996': '64', '1994/1995': '63', '1993/1994': '62', '1992/1993': '61', '1991/1992': '60', '1990/1991': '59', '1989/1990': '58', '1988/1989': '57', '1987/1988': '56', '1986/1987': '55', '1985/1986': '54', '1984/1985': '53', '1983/1984': '52', '1982/1983': '51', '1981/1982': '50', '1980/1981': '49', '1979/1980': '48', '1978/1979': '47', '1977/1978': '46', '1976/1977': '45', '1975/1976': '44', '1974/1975': '43', '1973/1974': '42', '1972/1973': '41', '1971/1972': '40', '1970/1971': '39', '1969/1970': '38', '1968/1969': '37', '1967/1968': '36', '1966/1967': '35', '1965/1966': '34', '1964/1965': '33', '1963/1964': '32', '1962/1963': '31', '1961/1962': '30', '1960/1961': '29', '1959/1960': '28', '1958/1959': '27', '1957/1958': '26', '1956/1957': '25', '1955/1956': '24', '1954/1955': '23', '1953/1954': '22', '1952/1953': '21', '1951/1952': '20', '1950/1951': '19', '1949/1950': '18', '1948/1949': '17', '1947/1948': '16', '1946/1947': '15', '1945/1946': '14', '1938/1939': '7', '1937/1938': '6', '1936/1937': '5', '1935/1936': '4', '1934/1935': '3', '1933/1934': '2', '1932/1933': '1'}\n",
    "#save_obj(dic, 'season_dic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load season dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "season_dic = load_obj('season_dic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [selenium_url_to_tree] download url final output as a tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to retrieve our URLs HTML as elementree object to parse it later. The problem is the URLs we are looking for are using Javascript to generate part of HTML page. The basic method 'urlopen' won't work in that case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get url html as elementtree using selenium.webdriver\n",
    "def selenium_url_to_tree(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    htmlSource = driver.page_source\n",
    "    tree = lh.fromstring(htmlSource)\n",
    "    return tree\n",
    "\n",
    "# HOW IT WORKS....\n",
    "# open driver: that will open firefox window\n",
    "#driver = webdriver.Firefox()\n",
    "\n",
    "# construct the trees only once\n",
    "#results_tree = selenium_url_to_tree(driver,week_url)\n",
    "\n",
    "# close firefox window once done\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [handle_accent] get rid of weird accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to find a much better way to handle all that (using unicode)\n",
    "def handle_accent(s):\n",
    "    s = s.replace(\"ã¨\", \"e\")\n",
    "    s = s.replace(\"ã©\", \"e\")\n",
    "    s = s.replace(\"ã¯\", \"i\")\n",
    "    s = s.replace(\"ã\", \"a\")\n",
    "    s = s.replace(\"a«\", \"e\")\n",
    "    s = s.replace(\"a¢\", \"a\")\n",
    "    s = s.replace(\"a§\", \"c\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get_week_url] construct week url from season_id and week_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_week_url(competition, season_id, week_id):\n",
    "    template_url = 'http://www.ligue1.com/' + dic_competition_url[competition] + '/calendrier_resultat#sai=%season_id%&jour=%week_id%'\n",
    "    season_url = template_url.replace(\"%season_id%\", str(season_id))\n",
    "    return season_url.replace(\"%week_id%\", str(week_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get_seasons_dictionary] construct dictionary of (season, season_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_seasons_dictionary(tree):\n",
    "    options = results_tree.findall('.//select[@name=\"saison\"]/option')\n",
    "    dic = {}\n",
    "    for option in options:\n",
    "        dic[option.text_content()] = option.attrib['value']\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get_coupeligue_stages_dictionary] construct dictionary {id,name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coupeligue_stages_dictionary(tree):\n",
    "    dic = {}\n",
    "    for elem in tree.findall('.//div[@id=\"journee_select\"]/select[@id=\"journee\"]/option'):\n",
    "        dic[elem.attrib['value']] = elem.text_content()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get_week_nb] get number of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_week_nb(tree):\n",
    "    lis = tree.findall('.//ul[@class=\"limite_hauteur\"]/li')\n",
    "    l = [x.text_content().strip() for x in lis if x.text_content()[:4]=='Week']\n",
    "    return len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get_scores] get scores for a single week in a season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used by dataframe\n",
    "cols = ['season', 'week', 'date', 'time', 'team_home', 'team_away', 'score_home', 'score_away', 'pen_home', 'pen_away']\n",
    "\n",
    "def get_scores(tree, competition, season, week_id):\n",
    "    \n",
    "    # get tables html element from the tree\n",
    "    tables = tree.findall('.//div[@id=\"tableaux_rencontres\"]//table')\n",
    "    \n",
    "    # get stage name from week id\n",
    "    if(week_id == 82):\n",
    "        # ligue1 playoffs\n",
    "        stage = \"Play-off\"\n",
    "    elif(week_id==-1):\n",
    "        # trophee des champs\n",
    "        stage = \"Final\"\n",
    "    elif(week_id > 40):\n",
    "        # coupe de la ligue\n",
    "        stage = get_coupeligue_stages_dictionary(tree)[str(week_id)]\n",
    "    else:\n",
    "        # ligue 1\n",
    "        stage = \"Week\" + str(week_id)\n",
    "    \n",
    "    # log current process\n",
    "    logger.info(\"Processing season {0}, {1}\".format(season, stage))\n",
    "    \n",
    "    # store results\n",
    "    data = []\n",
    "    \n",
    "    for table in tables:\n",
    "        \n",
    "        # get date\n",
    "        caption = table.find('.//caption').text_content().split()\n",
    "        date = caption[5] + \"-\" + caption[4] + \"-\" + caption[3]\n",
    "        \n",
    "        # get all rows\n",
    "        trs = table.findall('.//tbody/tr')\n",
    "        \n",
    "        for tr in trs:\n",
    "            \n",
    "            try:\n",
    "                time = tr.find('.//td[@class=\"horaire \"]').text_content().strip()\n",
    "            except:\n",
    "                try:\n",
    "                    # check for postponed game exception\n",
    "                    time = tr.find('.//td[@class=\"horaire reporte \"]').text_content().strip()\n",
    "                    if(time == 'Postponed'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        logger.error(\"time value not correct: {0}\".format(time))\n",
    "                        continue\n",
    "                except:\n",
    "                    # unknown error: log and continue\n",
    "                    logger.error(\"Unknown exception while fetching time\")\n",
    "                    continue\n",
    "            try:\n",
    "                team_home = tr.find('.//td[@class=\"domicile\"]').text_content().strip()\n",
    "                team_away = tr.find('.//td[@class=\"exterieur\"]').text_content().strip()\n",
    "                \n",
    "                score = tr.find('.//td[@class=\"stats\"]/a').text_content().strip()\n",
    "                spanElem = tr.findall('.//td[@class=\"stats\"]/a/span')\n",
    "\n",
    "                scorePen = None\n",
    "                \n",
    "                # 1 span element: could be extra time indicator or penalty kick...\n",
    "                if(len(spanElem)==1):\n",
    "                    \n",
    "                    # since 2016/2017: no more extra time for coupe de la ligue\n",
    "                    if(competition=='coupe-de-la-ligue' and int(season_dic[season]) >= int(season_dic['2016/2017'])):\n",
    "                        scorePen = spanElem[0].text_content().strip()\n",
    "                        score = score.replace(scorePen, '')\n",
    "                        scorePen = scorePen.replace('on pens', '')\n",
    "                        scorePen = scorePen.replace(' ', '')\n",
    "                    \n",
    "                    # if trophee des champions, for sure it's penalty kick indicator only (never any extra time for this)\n",
    "                    elif(competition=='trophee-des-champions'):\n",
    "                        scorePen = spanElem[0].text_content().strip()\n",
    "                        score = score.replace(scorePen, '')\n",
    "                        scorePen = scorePen.replace('on pens', '')\n",
    "                        scorePen = scorePen.replace(' ', '')\n",
    "                                \n",
    "                # 2 span elements: need to handle extra time score + penalty kicks..\n",
    "                if(len(spanElem)==2):\n",
    "                    scorePen = spanElem[1].text_content().strip()\n",
    "                    score = score.replace(scorePen, '')\n",
    "                    scorePen = scorePen.replace('on pens', '')\n",
    "                    scorePen = scorePen.replace(' ', '')\n",
    "\n",
    "                score = score.replace('a.e.t.', '')\n",
    "                score = score.replace(' ', '')\n",
    "                \n",
    "                score_home = score.split('-')[0]\n",
    "                score_away = score.split('-')[1]\n",
    "                \n",
    "                pen_home = None\n",
    "                pen_away = None\n",
    "                if(scorePen != None):\n",
    "                    pen_home = scorePen.split('-')[0]\n",
    "                    pen_away = scorePen.split('-')[1]                \n",
    "                \n",
    "            except:\n",
    "                # if any exception when retrieving these attributes, log and raise (non recoverable exception)\n",
    "                logger.error(\"Exception while fetching main game data: {0}\".format(traceback.print_exc()))\n",
    "                \n",
    "                # better to not block on any game error, so we now use 'continue' i/o 'raise'\n",
    "                #raise\n",
    "                continue\n",
    "            \n",
    "            #link = tr.find('.//td[@class=\"video\"]/a').attrib['href']\n",
    "            data += [[season, stage, date, time, team_home, team_away, score_home, score_away, pen_home, pen_away]]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [process_single_week] process a single week of data (web connection is wrapped inside)\n",
    "## => \"live\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_single_week(competition, season, week_id):\n",
    "    # get season id from season dictionary\n",
    "    season_id = season_dic[season]\n",
    "    # open driver: that will open firefox window\n",
    "    driver = webdriver.Firefox()\n",
    "    # get the tree from week url\n",
    "    tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, week_id))\n",
    "    # process one week\n",
    "    data = get_scores(tree, competition, season, week_id)\n",
    "    # we are done with firefox...\n",
    "    driver.quit()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [season_df_to_csv] helper to save a season results from dataframe to csv file, with proper file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def season_df_to_csv(df, competition, season):\n",
    "    season_string = season.split('/')[0] + '_' + season.split('/')[1]\n",
    "    filename = competition + '_' + season_string + '.csv'\n",
    "    df.to_csv(os.path.join(root_path, competition, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [process_ligue1_seasons] process set of ligue1 seasons (historical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_ligue1_seasons(season_to_process):\n",
    "    \n",
    "    competition = 'ligue1'\n",
    "    \n",
    "    for season in season_to_process:\n",
    "    \n",
    "        # get season id\n",
    "        season_id = season_dic[season]\n",
    "        \n",
    "        # first week id\n",
    "        first_week_id = 1\n",
    "        \n",
    "        # get the tree from first week url\n",
    "        tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, first_week_id))\n",
    "\n",
    "        # get week number\n",
    "        week_nb = get_week_nb(tree)\n",
    "\n",
    "        # empty list to store results\n",
    "        data = []\n",
    "\n",
    "        # process first week url which we already have\n",
    "        data += get_scores(tree, competition, season, first_week_id)\n",
    "\n",
    "        # browse remaining weeks of data\n",
    "        for i in range(2,week_nb + 1):\n",
    "            tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, i))\n",
    "            data += get_scores(tree, competition, season, i)\n",
    "\n",
    "        #check on data table\n",
    "        nb_team = (week_nb/2) + 1\n",
    "        nb_game = (week_nb * nb_team)/2\n",
    "        if(len(data)  != nb_game):\n",
    "            # log error\n",
    "            logger.error(\"error while processing season {0}: data len ({1}) doesn't match number of game ({2}) \".format(season, len(data), nb_game))\n",
    "            # go to next iteration\n",
    "            continue\n",
    "\n",
    "        # if check was passed, we are going to save data as panda dataframe\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "        # save df as csv file\n",
    "        season_df_to_csv(df, competition, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [process_playoffs] process play-off pages (works only for ligue1 competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_playoffs(season_to_process):\n",
    "    \n",
    "    competition = 'ligue1'\n",
    "    \n",
    "    for season in season_to_process:\n",
    "    \n",
    "        # get season id\n",
    "        season_id = season_dic[season]\n",
    "\n",
    "        # get the tree from first week url\n",
    "        tree = selenium_url_to_tree(driver,get_week_url(season_id, 82))\n",
    "\n",
    "        # empty list to store results\n",
    "        data = []\n",
    "        \n",
    "        try:\n",
    "            # process play-off page (id=82)\n",
    "            data = get_scores(tree, competition, season, 82)\n",
    "        except:\n",
    "            logger.error(\"error while processing play-off web page for season {0}: skip..\".format(season))\n",
    "            continue\n",
    "            \n",
    "        # check on data table\n",
    "        # there shouldn't be more than 10 games.. (usually maybe 6 games max, not sure...)\n",
    "        nb_game = 10\n",
    "        if(len(data) == 0):\n",
    "            # log error\n",
    "            logger.error(\"no data to process for season {0}\".format(season))\n",
    "            # go to next iteration\n",
    "            continue\n",
    "        elif (len(data)  > nb_game):\n",
    "            # log error\n",
    "            logger.error(\"error while processing season {0}: data len ({1}) is the max number of game we have set ({2}) \".format(season, len(data), nb_game))\n",
    "            # go to next iteration\n",
    "            continue\n",
    "\n",
    "        # if check was passed, we are going to save data as panda dataframe\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "        # save df as csv file\n",
    "        season_df_to_csv(df, competition, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [process_coupeligue_seasons] process set of coupe de la ligue seasons (historical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_coupeligue_seasons(season_to_process):\n",
    "    \n",
    "    competition = 'coupe-de-la-ligue'\n",
    "    \n",
    "    for season in season_to_process:\n",
    "    \n",
    "        print('processing season {0}'.format(season))\n",
    "            \n",
    "        # get season id\n",
    "        season_id = season_dic[season]\n",
    "        \n",
    "        # first week id\n",
    "        first_week_id = 47\n",
    "        \n",
    "        # get the tree from first week url\n",
    "        tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, first_week_id))\n",
    "        \n",
    "        # get list of week_id\n",
    "        week_id_list = [int(x) for x in get_coupeligue_stages_dictionary(tree).keys()]\n",
    "\n",
    "        # empty list to store results\n",
    "        data = []\n",
    "\n",
    "        # process first week url which we already have\n",
    "        data += get_scores(tree, competition, season, first_week_id)\n",
    "\n",
    "        # browse remaining weeks of data\n",
    "        for i in week_id_list[1:]:\n",
    "            tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, i))\n",
    "            data += get_scores(tree, competition, season, i)\n",
    "\n",
    "        # check on data table\n",
    "        # TO DO\n",
    "        \n",
    "        # if check was passed, we are going to save data as panda dataframe\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "        # save df as csv file\n",
    "        season_df_to_csv(df, competition, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [process_trophee_seasons] process set of trophee des champs seasons (historical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_trophee_seasons(season_to_process):\n",
    "    \n",
    "    competition = 'trophee-des-champions'\n",
    "    \n",
    "    for season in season_to_process:\n",
    "        \n",
    "        print('processing season {0}'.format(season))\n",
    "        \n",
    "        # get season id\n",
    "        season_id = season_dic[season]\n",
    "        \n",
    "        # first week id\n",
    "        first_week_id = -1\n",
    "        \n",
    "        # get the tree from first week url\n",
    "        tree = selenium_url_to_tree(driver,get_week_url(competition, season_id, first_week_id))\n",
    "\n",
    "        # process first week url: the only one since trophee des champions is just one game\n",
    "        data = get_scores(tree, competition, season, first_week_id)\n",
    "        \n",
    "        # check on data table\n",
    "        # TO DO\n",
    "        \n",
    "        # if check was passed, we are going to save data as panda dataframe\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "        # save df as csv file\n",
    "        season_df_to_csv(df, competition, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unit test for process_single_week function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assert_scores(score, score_home, score_away, pen_home, pen_away):\n",
    "    assert_score = (score[6]==str(score_home) and score[7]==str(score_away))\n",
    "    \n",
    "    if(pen_home==None and pen_away==None):\n",
    "        assert_pen = (score[8]==None and score[9]==None)\n",
    "    else:\n",
    "        assert_pen = (score[8]==str(pen_home) and score[9]==str(pen_away))\n",
    "    return assert_score and assert_pen\n",
    "\n",
    "def test_process_single_week():\n",
    "    competition = 'coupe-de-la-ligue'\n",
    "    season = '2012/2013'\n",
    "    week_id = 47\n",
    "    data = process_single_week(competition, season, week_id)\n",
    "    assert assert_scores(data[1],3,3,5,4)\n",
    "    assert assert_scores(data[2],0,0,5,4)\n",
    "    assert assert_scores(data[6],2,1,None,None)\n",
    "\n",
    "    competition = 'coupe-de-la-ligue'\n",
    "    season = '2016/2017'\n",
    "    week_id = 47\n",
    "    data = process_single_week(competition, season, week_id)\n",
    "    assert assert_scores(data[0],2,5,None,None)\n",
    "    assert assert_scores(data[2],0,0,5,3)\n",
    "    assert assert_scores(data[7],1,1,1,3)\n",
    "\n",
    "    competition = 'trophee-des-champions'\n",
    "    season = '2001/2002'\n",
    "    week_id = -1\n",
    "    data = process_single_week(competition, season, week_id)\n",
    "    assert assert_scores(data[0],1,4,None,None)\n",
    "\n",
    "    competition = 'trophee-des-champions'\n",
    "    season = '1995/1996'\n",
    "    week_id = -1\n",
    "    data = process_single_week(competition, season, week_id)\n",
    "    assert assert_scores(data[0],2,2,6,5)\n",
    "\n",
    "    competition = 'ligue1'\n",
    "    season = '2008/2009'\n",
    "    week_id = 1\n",
    "    data = process_single_week(competition, season, week_id)\n",
    "    assert assert_scores(data[4],1,0,None,None)\n",
    "\n",
    "    print(\"all good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test for get_coupeligue_stages_dictionary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_get_coupeligue_stages_dictionary():\n",
    "    \n",
    "    driver = webdriver.Firefox()\n",
    "    \n",
    "    # test season 1994/1995, 1st Round\n",
    "    tree = selenium_url_to_tree(driver,'http://www.ligue1.com/coupeLigue/calendrier_resultat#sai=63&jour=47')\n",
    "    stage = get_coupeligue_stages_dictionary(tree)[str(47)]\n",
    "    assert stage == '1st Round'\n",
    "    \n",
    "    # test season 1994/1995, Round of 32\n",
    "    tree = selenium_url_to_tree(driver,'http://www.ligue1.com/coupeLigue/calendrier_resultat#sai=63&jour=56')\n",
    "    stage = get_coupeligue_stages_dictionary(tree)[str(56)]\n",
    "    assert stage == 'Round of 32'\n",
    "    \n",
    "    print(\"all good!\")\n",
    "    \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_process_single_week()\n",
    "#test_get_coupeligue_stages_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test tree creation via selenium plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#driver = webdriver.Firefox()\n",
    "#tree = selenium_url_to_tree(driver,'http://www.ligue1.com/coupeLigue/calendrier_resultat#sai=63&jour=47')\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test process a single week with different competition inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get season id from season dictionary\n",
    "#season_id = season_dic['2012/2013']\n",
    "# open driver: that will open firefox window\n",
    "#driver = webdriver.Firefox()\n",
    "# get the tree from week url\n",
    "#tree = selenium_url_to_tree(driver,get_week_url('coupe-de-la-ligue', season_id, 47))\n",
    "# we are done with firefox...\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process set of seasons/play-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasons to process for ligue1:\n",
      " ['2009/2010', '2010/2011', '2011/2012', '2012/2013', '2013/2014', '2014/2015', '2015/2016', '2016/2017']\n",
      "\n",
      "seasons to process for coupe de la ligue:\n",
      " ['1994/1995', '1995/1996', '1996/1997', '1997/1998', '1998/1999', '1999/2000', '2000/2001', '2001/2002', '2002/2003', '2003/2004', '2004/2005', '2005/2006', '2006/2007', '2007/2008', '2008/2009', '2009/2010', '2010/2011', '2011/2012', '2012/2013', '2013/2014', '2014/2015', '2015/2016', '2016/2017']\n",
      "\n",
      "seasons to process for trophee des champion:\n",
      " ['1995/1996', '1997/1998', '1998/1999', '1999/2000', '2000/2001', '2001/2002', '2002/2003', '2003/2004', '2004/2005', '2005/2006', '2006/2007', '2007/2008', '2008/2009', '2009/2010', '2010/2011', '2011/2012', '2012/2013', '2013/2014', '2014/2015', '2015/2016', '2016/2017']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#season_to_process = sorted(season_dic.keys())[-24:-1]\n",
    "season_to_process_coupeligue = sorted(season_dic.keys())[-24:-1]\n",
    "season_to_process_trophee = ['1995/1996', '1997/1998', '1998/1999', '1999/2000', '2000/2001', '2001/2002', '2002/2003', '2003/2004', '2004/2005', '2005/2006', '2006/2007', '2007/2008', '2008/2009', '2009/2010', '2010/2011', '2011/2012', '2012/2013', '2013/2014', '2014/2015', '2015/2016', '2016/2017']\n",
    "\n",
    "# manual:\n",
    "season_to_process = ['2009/2010', '2010/2011', '2011/2012', '2012/2013', '2013/2014', '2014/2015', '2015/2016', '2016/2017']\n",
    "\n",
    "print('seasons to process for ligue1:\\n {0}\\n'.format(season_to_process))\n",
    "print('seasons to process for coupe de la ligue:\\n {0}\\n'.format(season_to_process_coupeligue))\n",
    "print('seasons to process for trophee des champion:\\n {0}\\n'.format(season_to_process_trophee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing season 1995/1996\n",
      "processing season 1997/1998\n",
      "processing season 1998/1999\n",
      "processing season 1999/2000\n",
      "processing season 2000/2001\n",
      "processing season 2001/2002\n",
      "processing season 2002/2003\n",
      "processing season 2003/2004\n",
      "processing season 2004/2005\n",
      "processing season 2005/2006\n",
      "processing season 2006/2007\n",
      "processing season 2007/2008\n",
      "processing season 2008/2009\n",
      "processing season 2009/2010\n",
      "processing season 2010/2011\n",
      "processing season 2011/2012\n",
      "processing season 2012/2013\n",
      "processing season 2013/2014\n",
      "processing season 2014/2015\n",
      "processing season 2015/2016\n",
      "processing season 2016/2017\n"
     ]
    }
   ],
   "source": [
    "# open driver: that will open firefox window\n",
    "#driver = webdriver.Firefox()\n",
    "\n",
    "# handle ligue 1 competition\n",
    "# process all seasons\n",
    "#process_ligue1_seasons(season_to_process)\n",
    "# process all ligue 1 play-offs (if any)\n",
    "#process_ligue1_playoffs(season_to_process)\n",
    "\n",
    "# handle other french competitions available on www.ligue1.com\n",
    "#process_coupeligue_seasons(season_to_process)\n",
    "#process_trophee_seasons(season_to_process_trophee)\n",
    "\n",
    "# we are done with firefox...\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dtypeCount =[df.iloc[:,i].apply(type).value_counts() for i in range(df.shape[1])]\n",
    "#dtypeCount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
